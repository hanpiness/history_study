{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分验证集\n",
    "total_num = len(train_images)\n",
    "valid_split = 0.2           # 验证集的比例占20%\n",
    "train_num = int(total_num*(1-valid_split))  # 训练集的数目\n",
    "\n",
    "train_x = train_images[:train_num]\n",
    "train_y = train_labels[:train_num]\n",
    "\n",
    "valid_x = train_images[train_num:]\n",
    "valid_y = train_labels[train_num:]\n",
    "\n",
    "test_x = test_images\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据塑形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把(28,28)的结构拉直为一行 784\n",
    "train_x = train_x.reshape(-1,784)\n",
    "valid_x = valid_x.reshape(-1,784)\n",
    "test_x = test_x.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tf.cast(train_x/255.0,tf.float32)\n",
    "valid_x = tf.cast(valid_x/255.0,tf.float32)\n",
    "test_x = tf.cast(test_x/255.0,tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标签数据独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对标签数据进行独热编码\n",
    "train_y = tf.one_hot(train_y,depth = 10)\n",
    "valid_y = tf.one_hot(valid_y,depth = 10)\n",
    "test_y = tf.one_hot(test_y,depth = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建待优化变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第一层隐藏层权重和偏置项变量\n",
    "Input_Dim = 784\n",
    "H1_NN = 64\n",
    "W1 = tf.Variable(tf.random.normal([Input_Dim, H1_NN],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "B1 = tf.Variable(tf.zeros([H1_NN]),dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义输出层权重和偏置项变量\n",
    "Output_Dim = 10\n",
    "W2 = tf.Variable(tf.random.normal([H1_NN, Output_Dim],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "B2 = tf.Variable(tf.zeros([Output_Dim]),dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建立待优化变量列表\n",
    "W = [W1, W2]\n",
    "B = [B1, B2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x,w,b):\n",
    "    x = tf.matmul(x,w[0]) + b[0]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x,w[1]) + b[1]\n",
    "    pred = tf.nn.softmax(x)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "\n",
    "def loss(x,y,w,b):\n",
    "    pred = model(x,w,b)   # 计算模型预测值和标签值的差异\n",
    "    loss_  = tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_) # 求均值，得出均方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_epochs = 20 #训练轮数\n",
    "batch_size  = 50  #单次训练样本数（批次大小）\n",
    "learning_rate = 0.01 # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义梯度计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算样本数据[x，y]在参数[w,b]点上的梯度\n",
    "def grad(x,y,w,b):\n",
    "    var_list = w + b\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x,y,w,b)\n",
    "    return tape.gradient(loss_,var_list) # 返回梯度向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adam优化器\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(x,y,w,b):\n",
    "    pred = model(x,w,b)# 计算模型预测值和标签值的差异\n",
    "    # 检查预测值类别tf.argmax(pred,1)与实际类别tf.argmax(pred,1)的匹配情况\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    # 准确率，将布尔值转换为浮点数，并计算平均值\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1,train_loss=2.7928,train_acc=0.8086,val_loss=2.7496,val_acc=0.8129\n",
      "epoch=  2,train_loss=0.8854,train_acc=0.9288,val_loss=0.9051,val_acc=0.9281\n",
      "epoch=  3,train_loss=0.6433,train_acc=0.9466,val_loss=0.7304,val_acc=0.9392\n",
      "epoch=  4,train_loss=0.6166,train_acc=0.9465,val_loss=0.6655,val_acc=0.9428\n",
      "epoch=  5,train_loss=0.5202,train_acc=0.9529,val_loss=0.5947,val_acc=0.9463\n",
      "epoch=  6,train_loss=0.4433,train_acc=0.9591,val_loss=0.5413,val_acc=0.9523\n",
      "epoch=  7,train_loss=0.4534,train_acc=0.9567,val_loss=0.5367,val_acc=0.9497\n",
      "epoch=  8,train_loss=0.3502,train_acc=0.9651,val_loss=0.4385,val_acc=0.9576\n",
      "epoch=  9,train_loss=0.3049,train_acc=0.9692,val_loss=0.4644,val_acc=0.9563\n",
      "epoch= 10,train_loss=0.3007,train_acc=0.9693,val_loss=0.4571,val_acc=0.9553\n",
      "epoch= 11,train_loss=0.2651,train_acc=0.9728,val_loss=0.4097,val_acc=0.9588\n",
      "epoch= 12,train_loss=0.3210,train_acc=0.9645,val_loss=0.4902,val_acc=0.9522\n",
      "epoch= 13,train_loss=0.2354,train_acc=0.9749,val_loss=0.3986,val_acc=0.9622\n",
      "epoch= 14,train_loss=0.2053,train_acc=0.9770,val_loss=0.3837,val_acc=0.9603\n",
      "epoch= 15,train_loss=0.2177,train_acc=0.9752,val_loss=0.4004,val_acc=0.9589\n",
      "epoch= 16,train_loss=0.2252,train_acc=0.9749,val_loss=0.3953,val_acc=0.9605\n",
      "epoch= 17,train_loss=0.2240,train_acc=0.9724,val_loss=0.4071,val_acc=0.9567\n",
      "epoch= 18,train_loss=0.2003,train_acc=0.9753,val_loss=0.4013,val_acc=0.9572\n",
      "epoch= 19,train_loss=0.2000,train_acc=0.9782,val_loss=0.4150,val_acc=0.9606\n",
      "epoch= 20,train_loss=0.2217,train_acc=0.9756,val_loss=0.4753,val_acc=0.9544\n"
     ]
    }
   ],
   "source": [
    "steps = int(train_num/batch_size)     #一轮训练有多少批次\n",
    "\n",
    "loss_list_train = []  #用于保存训练集loss值的列表\n",
    "loss_list_valid = []  #用于保存验证集loss值的列表\n",
    "acc_list_train = []   #用于保存训练集acc值的列表\n",
    "acc_list_valid = []   #用于保存验证集Acc值的列表\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(steps):\n",
    "        xs = train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys = train_y[step*batch_size:(step+1)*batch_size]\n",
    "        grads = grad(xs,ys,W,B)\n",
    "        optimizer.apply_gradients(zip(grads,W+B))  # 优化器根据梯度自动调节值\n",
    "    \n",
    "    loss_train = loss(train_x,train_y,W,B).numpy()\n",
    "    loss_valid = loss(valid_x,valid_y,W,B).numpy()\n",
    "    acc_train = accuracy(train_x,train_y,W,B).numpy()\n",
    "    acc_valid = accuracy(valid_x,valid_y,W,B).numpy()\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "    acc_list_train.append(acc_train)\n",
    "    acc_list_valid.append(acc_valid)\n",
    "    print(\"epoch={:3d},train_loss={:.4f},train_acc={:.4f},val_loss={:.4f},val_acc={:.4f}\".format(epoch+1,loss_train,acc_train,loss_valid,acc_valid))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "env-tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
