{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 划分验证集\n",
    "total_num = len(train_images)\n",
    "valid_split = 0.2           # 验证集的比例占20%\n",
    "train_num = int(total_num*(1-valid_split))  # 训练集的数目\n",
    "\n",
    "train_x = train_images[:train_num]\n",
    "train_y = train_labels[:train_num]\n",
    "\n",
    "valid_x = train_images[train_num:]\n",
    "valid_y = train_labels[train_num:]\n",
    "\n",
    "test_x = test_images\n",
    "test_y = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据塑形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把(28,28)的结构拉直为一行 784\n",
    "train_x = train_x.reshape(-1,784)\n",
    "valid_x = valid_x.reshape(-1,784)\n",
    "test_x = test_x.reshape(-1,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tf.cast(train_x/255.0,tf.float32)\n",
    "valid_x = tf.cast(valid_x/255.0,tf.float32)\n",
    "test_x = tf.cast(test_x/255.0,tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 标签数据独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#对标签数据进行独热编码\n",
    "train_y = tf.one_hot(train_y,depth = 10)\n",
    "valid_y = tf.one_hot(valid_y,depth = 10)\n",
    "test_y = tf.one_hot(test_y,depth = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建待优化变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第一层隐藏层权重和偏置项变量\n",
    "Input_Dim = 784\n",
    "H1_NN = 64\n",
    "W1 = tf.Variable(tf.random.normal([Input_Dim, H1_NN],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "B1 = tf.Variable(tf.zeros([H1_NN]),dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义第2层隐藏层权重和偏置项变量\n",
    "H2_NN = 32\n",
    "W2 = tf.Variable(tf.random.normal([H1_NN,H2_NN],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "B2 = tf.Variable(tf.zeros([H2_NN]),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义输出层权重和偏置项变量\n",
    "Output_Dim = 10\n",
    "W3 = tf.Variable(tf.random.normal([H2_NN, Output_Dim],mean=0.0,stddev=1.0,dtype=tf.float32))\n",
    "B3 = tf.Variable(tf.zeros([Output_Dim]),dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 建立待优化变量列表\n",
    "W = [W1, W2,W3]\n",
    "B = [B1, B2,B3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(x,w,b):\n",
    "    x = tf.matmul(x,w[0]) + b[0]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x,w[1]) + b[1]\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.matmul(x,w[2]) + b[2]\n",
    "    pred = tf.nn.softmax(x)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义交叉熵损失函数\n",
    "\n",
    "def loss(x,y,w,b):\n",
    "    pred = model(x,w,b)   # 计算模型预测值和标签值的差异\n",
    "    loss_  = tf.keras.losses.categorical_crossentropy(y_true=y,y_pred=pred)\n",
    "    return tf.reduce_mean(loss_) # 求均值，得出均方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置训练超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_epochs = 30 #训练轮数\n",
    "batch_size  = 50  #单次训练样本数（批次大小）\n",
    "learning_rate = 0.005 # 学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义梯度计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算样本数据[x，y]在参数[w,b]点上的梯度\n",
    "def grad(x,y,w,b):\n",
    "    var_list = w + b\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_ = loss(x,y,w,b)\n",
    "    return tape.gradient(loss_,var_list) # 返回梯度向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adam优化器\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(x,y,w,b):\n",
    "    pred = model(x,w,b)# 计算模型预测值和标签值的差异\n",
    "    # 检查预测值类别tf.argmax(pred,1)与实际类别tf.argmax(pred,1)的匹配情况\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "    # 准确率，将布尔值转换为浮点数，并计算平均值\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  1,train_loss=5.9346,train_acc=0.6282,val_loss=5.8398,val_acc=0.6343\n",
      "epoch=  2,train_loss=5.7867,train_acc=0.6390,val_loss=5.7049,val_acc=0.6436\n",
      "epoch=  3,train_loss=5.6381,train_acc=0.6484,val_loss=5.5691,val_acc=0.6532\n",
      "epoch=  4,train_loss=5.5167,train_acc=0.6561,val_loss=5.4788,val_acc=0.6582\n",
      "epoch=  5,train_loss=5.5073,train_acc=0.6570,val_loss=5.5567,val_acc=0.6544\n",
      "epoch=  6,train_loss=5.4747,train_acc=0.6592,val_loss=5.4273,val_acc=0.6620\n",
      "epoch=  7,train_loss=5.3582,train_acc=0.6665,val_loss=5.3229,val_acc=0.6687\n",
      "epoch=  8,train_loss=5.3214,train_acc=0.6689,val_loss=5.2860,val_acc=0.6711\n",
      "epoch=  9,train_loss=5.2692,train_acc=0.6721,val_loss=5.2594,val_acc=0.6727\n",
      "epoch= 10,train_loss=5.3484,train_acc=0.6672,val_loss=5.3207,val_acc=0.6692\n",
      "epoch= 11,train_loss=5.3244,train_acc=0.6686,val_loss=5.3386,val_acc=0.6678\n",
      "epoch= 12,train_loss=5.2254,train_acc=0.6752,val_loss=5.2083,val_acc=0.6763\n",
      "epoch= 13,train_loss=5.3530,train_acc=0.6671,val_loss=5.3367,val_acc=0.6678\n",
      "epoch= 14,train_loss=5.2919,train_acc=0.6709,val_loss=5.3052,val_acc=0.6701\n",
      "epoch= 15,train_loss=5.3005,train_acc=0.6704,val_loss=5.3064,val_acc=0.6702\n",
      "epoch= 16,train_loss=5.2552,train_acc=0.6732,val_loss=5.2440,val_acc=0.6738\n",
      "epoch= 17,train_loss=5.5795,train_acc=0.6526,val_loss=5.5562,val_acc=0.6539\n",
      "epoch= 18,train_loss=5.3172,train_acc=0.6694,val_loss=5.3229,val_acc=0.6692\n",
      "epoch= 19,train_loss=5.1921,train_acc=0.6774,val_loss=5.1956,val_acc=0.6772\n",
      "epoch= 20,train_loss=5.2816,train_acc=0.6716,val_loss=5.2653,val_acc=0.6727\n",
      "epoch= 21,train_loss=3.2682,train_acc=0.7949,val_loss=3.0814,val_acc=0.8068\n",
      "epoch= 22,train_loss=2.8056,train_acc=0.8244,val_loss=2.6651,val_acc=0.8332\n",
      "epoch= 23,train_loss=2.5886,train_acc=0.8381,val_loss=2.5063,val_acc=0.8434\n",
      "epoch= 24,train_loss=2.4450,train_acc=0.8474,val_loss=2.3666,val_acc=0.8523\n",
      "epoch= 25,train_loss=2.4502,train_acc=0.8473,val_loss=2.3945,val_acc=0.8509\n",
      "epoch= 26,train_loss=2.6577,train_acc=0.8339,val_loss=2.5958,val_acc=0.8376\n",
      "epoch= 27,train_loss=2.3187,train_acc=0.8553,val_loss=2.3018,val_acc=0.8567\n",
      "epoch= 28,train_loss=2.3118,train_acc=0.8558,val_loss=2.2527,val_acc=0.8591\n",
      "epoch= 29,train_loss=2.3031,train_acc=0.8562,val_loss=2.2516,val_acc=0.8597\n",
      "epoch= 30,train_loss=2.4090,train_acc=0.8498,val_loss=2.3430,val_acc=0.8535\n"
     ]
    }
   ],
   "source": [
    "steps = int(train_num/batch_size)     #一轮训练有多少批次\n",
    "\n",
    "loss_list_train = []  #用于保存训练集loss值的列表\n",
    "loss_list_valid = []  #用于保存验证集loss值的列表\n",
    "acc_list_train = []   #用于保存训练集acc值的列表\n",
    "acc_list_valid = []   #用于保存验证集Acc值的列表\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    for step in range(steps):\n",
    "        xs = train_x[step*batch_size:(step+1)*batch_size]\n",
    "        ys = train_y[step*batch_size:(step+1)*batch_size]\n",
    "        grads = grad(xs,ys,W,B)\n",
    "        optimizer.apply_gradients(zip(grads,W+B))  # 优化器根据梯度自动调节值\n",
    "    \n",
    "    loss_train = loss(train_x,train_y,W,B).numpy()\n",
    "    loss_valid = loss(valid_x,valid_y,W,B).numpy()\n",
    "    acc_train = accuracy(train_x,train_y,W,B).numpy()\n",
    "    acc_valid = accuracy(valid_x,valid_y,W,B).numpy()\n",
    "    loss_list_train.append(loss_train)\n",
    "    loss_list_valid.append(loss_valid)\n",
    "    acc_list_train.append(acc_train)\n",
    "    acc_list_valid.append(acc_valid)\n",
    "    print(\"epoch={:3d},train_loss={:.4f},train_acc={:.4f},val_loss={:.4f},val_acc={:.4f}\".format(epoch+1,loss_train,acc_train,loss_valid,acc_valid))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "env-tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
